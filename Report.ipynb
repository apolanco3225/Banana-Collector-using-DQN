{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banana Collector using Deep Reinforcement Learning \n",
    "\n",
    "For this project, it's trained an agent to navigate (and collect bananas!) in a large, square world.\n",
    "\n",
    "<img src='https://s3.amazonaws.com/video.udacity-data.com/topher/2018/June/5b1ab4b0_banana/banana.gif' align='center'>\n",
    "\n",
    "### Explanation of how Deep Q Learning works\n",
    "Reinforcement Learning is the process of learning  by interacting in an environment through positive feedback, Q learning is a reinforcement learning technique that creates a policy of behaviour that maps actions and it's corresponding reward, for instance, in a chess game, in the case showed in the following image we can see that moving the pow two steps forward is the action that maximizes the probability of winning over all other actions. \n",
    "\n",
    "<img src='https://cdn-images-1.medium.com/max/716/1*srmv0GScAs6vObPfPj0-uQ.png' align='center'>\n",
    "\n",
    "The idea would be to create a Q-table that memorizes every possible configuration of the environment and the corresponding reward of all available actions, so, given any state in the environment, we can always choose an action that maximizes the reward given a state. \n",
    "\n",
    "<img src='https://cdn-images-1.medium.com/max/716/1*5ffOxpSgIJCYn0XccfFYUQ.png' align='center'>\n",
    "\n",
    "Depending on the problem we are working on this becomes unfisable, due to the consumption of memory and computational resources, like for instance, in the game of Go there are more configurations on the board than there are atoms in the universe, however this can not scale to  solve complex and interesting problems in real life. \n",
    "\n",
    "What's different with Deep Q Learning, the techinique used in this project, is that we don't have to store all those possible cases in the Q table, we only generalize the aproximation of the Q value function instead of remembering the reward of the actions. This is done by replacing the Qtable by a neural network.\n",
    "\n",
    "<img src='https://cdn-images-1.medium.com/max/1600/1*w5GuxedZ9ivRYqM_MLUxOQ.png' align='center'>\n",
    "\n",
    "Neural Networks are the state of the art algorithm in machine learning, they usually outperform all the other machine learning algorithms if big data and computational power are available in training. This is how we are getting features from the input images.\n",
    "\n",
    "<img src='https://cdn-images-1.medium.com/max/716/1*8coZ4g_pRtfyoHmsuzMH6g.png' align='center'>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Vanilla Deep Q Learning\n",
    "\n",
    "The main variation from the algorithm from the suggested paper  \"Playing atari with Deep Reinforcement Learning\" is that is not used a convolutional neural network, instead that was changed for a feed forward neural network that provides the input vector of the state.\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "Trained with the following parameters based on the ones from the paper:\n",
    "* BUFFER_SIZE = int(1e5)  \n",
    "* BATCH_SIZE = 64         \n",
    "* GAMMA = 0.99            \n",
    "* TAU = 1e-3              \n",
    "* LR = 5e-4               \n",
    "* UPDATE_EVERY = 4  \n",
    "\n",
    "\n",
    "3. Results \n",
    "<img src='drl_performance.png' align='center'>\n",
    "\n",
    "The model returned an average score of 11.49 after 100 episodes, a very successful model.\n",
    "4. Iprovements suggested for this project include:\n",
    "\n",
    "* Optimization modifyin hyperparameter \n",
    "* Changing the architechture to Double Deep Q Networks, Dueling Deep Q Networks or a combination of many of those (RAINBOW)\n",
    "* Prioritized Experience Replay\n",
    "* Learning from pixels instead \n",
    "    \n",
    "### Biography\n",
    "[Playing Atari with Deep Reinforcement Learning](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)<br>\n",
    "[How to use Q Learning in video games](https://www.youtube.com/watch?v=A5eihauRQvo)<br>\n",
    "[DQN Deep Q Network](https://medium.com/@jonathan_hui/rl-dqn-deep-q-network-e207751f7ae4)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
